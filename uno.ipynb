{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "dir_path = os.path.abspath(os.path.join('rlcard/'))\n",
    "if dir_path not in sys.path:\n",
    "    sys.path.append(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importされたmoduleの確認\n",
    "import rlcard\n",
    "print(rlcard.__file__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training DQN agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rlcard.agents.dqn_agent import DQNAgent\n",
    "from rlcard.agents.random_agent import  RandomAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = rlcard.make(\n",
    "    \"uno\",\n",
    "    config={\n",
    "        'allow_step_back': True,\n",
    "        'seed': 1234\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 環境の確認\n",
    "print(\"Number of actions:\", env.num_actions)\n",
    "print(\"Number of players:\", env.num_players)\n",
    "print(\"Shape of state:\", env.state_shape)\n",
    "print(\"Shape of action:\", env.action_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_dqn = DQNAgent(\n",
    "    num_actions=env.num_actions,\n",
    "    state_shape=env.state_shape[0],\n",
    "    mlp_layers=[64, 64, 64, 64, 64, 64],\n",
    "    save_path=\"experiments/dqn_result/\",\n",
    "    replay_memory_size=100000,\n",
    "    replay_memory_init_size=10000,\n",
    "    update_target_estimator_every=2000,\n",
    "    save_every=10000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.set_agents([agent_dqn for _ in range(env.num_players)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_env = rlcard.make(\n",
    "    \"uno\",\n",
    "    config={\n",
    "        'seed': 1234,\n",
    "    }\n",
    ")\n",
    "eval_env.set_agents([\n",
    "    agent_dqn,\n",
    "    RandomAgent(num_actions=env.num_actions),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rlcard.utils import (\n",
    "    set_seed,\n",
    "    tournament,\n",
    "    reorganize,\n",
    "    Logger,\n",
    "    plot_curve\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Logger(\"experiments/dqn_result/\") as logger:\n",
    "    for episode in range(10000):\n",
    "        tranjectories, payoffs = env.run(is_training=True)\n",
    "        \n",
    "        tranjectories = reorganize(tranjectories, payoffs)\n",
    "\n",
    "        for ts in tranjectories[0]:\n",
    "            agent_dqn.feed(ts)\n",
    "\n",
    "        if episode % 100 == 0:\n",
    "            logger.log_performance(\n",
    "                env.timestep,\n",
    "                tournament(\n",
    "                    eval_env,\n",
    "                    1000,\n",
    "                )[0]\n",
    "            )\n",
    "    \n",
    "    csv_path, fig_path = logger.csv_path, logger.fig_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_curve(csv_path, fig_path, \"DQN\", \"DQN vs Random\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training PPO agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rlcard.agents.random_agent import RandomAgent\n",
    "from rlcard.agents.ppo_agent import PPOAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = rlcard.make(\n",
    "    \"uno\",\n",
    "    config={\n",
    "        'allow_step_back': True,\n",
    "        'seed': 1234\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_ppo = PPOAgent(\n",
    "    state_shape=(4,4,15),\n",
    "    action_shape=(61,),\n",
    "    num_actions=env.num_actions,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.set_agents([agent_ppo for _ in range(env.num_players)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_env = rlcard.make(\n",
    "    \"uno\",\n",
    "    config={\n",
    "        'seed': 1234,\n",
    "    }\n",
    ")\n",
    "eval_env.set_agents([\n",
    "    agent_ppo,\n",
    "    RandomAgent(num_actions=env.num_actions),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rlcard.utils import (\n",
    "    set_seed,\n",
    "    tournament,\n",
    "    reorganize,\n",
    "    Logger,\n",
    "    plot_curve\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Logger(\"experiments/ppo_result/\") as logger:\n",
    "    for episode in range(10000):\n",
    "        tranjectories, payoffs = env.run(is_training=True)\n",
    "        \n",
    "        tranjectories = reorganize(tranjectories, payoffs)\n",
    "\n",
    "        for ts in tranjectories[0]:\n",
    "            agent_ppo.feed(ts)\n",
    "\n",
    "        if episode % 100 == 0:\n",
    "            logger.log_performance(\n",
    "                env.timestep,\n",
    "                tournament(\n",
    "                    eval_env,\n",
    "                    1000,\n",
    "                )[0]\n",
    "            )\n",
    "    \n",
    "    csv_path, fig_path = logger.csv_path, logger.fig_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_curve(csv_path, fig_path, \"PPO\", \"PPO vs Random\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
